from faster_whisper import WhisperModel
import torch

class AudioTranscriber:
    def __init__(self, model_size="tiny"):
        """
        Inicializa Faster-Whisper con aceleraciÃ³n MPS/GPU
        model_size: tiny, base, small, medium, large-v2
        """
        print(f"Cargando Faster-Whisper ({model_size}) con aceleraciÃ³n...")
        
        # Detectar dispositivo (MPS para Apple Silicon, CUDA para NVIDIA, CPU como fallback)
        if torch.backends.mps.is_available():
            device = "auto"  # faster-whisper auto-detecta MPS en Apple Silicon
            compute_type = "int8"  # Optimizado para Apple Silicon
            print("âœ… Usando aceleraciÃ³n Apple Silicon (MPS)")
        elif torch.cuda.is_available():
            device = "cuda"
            compute_type = "float16"
            print("âœ… Usando aceleraciÃ³n NVIDIA (CUDA)")
        else:
            device = "cpu"
            compute_type = "int8"
            print("âš ï¸  Usando CPU (mÃ¡s lento)")
        
        # Cargar modelo optimizado
        self.model = WhisperModel(
            model_size,
            device=device,
            compute_type=compute_type,
            num_workers=4  # Procesamiento paralelo
        )
        print(f"âœ… Faster-Whisper cargado (~4-5x mÃ¡s rÃ¡pido que Whisper normal)")
    
    def transcribe(self, audio_path: str) -> str:
        """
        Transcribe un archivo de audio a texto
        """
        print(f"ğŸ¤ Transcribiendo: {audio_path}")
        
        # Transcribir con faster-whisper
        segments, info = self.model.transcribe(
            audio_path,
            language="es",  # EspaÃ±ol
            beam_size=5,
            vad_filter=True,  # Filtro de detecciÃ³n de voz (mÃ¡s rÃ¡pido)
            vad_parameters=dict(min_silence_duration_ms=500)
        )
        
        # Detectar idioma
        print(f"ğŸ“ Idioma detectado: {info.language} ({info.language_probability:.2%} confianza)")
        print(f"â±ï¸  DuraciÃ³n del audio: {info.duration:.1f} segundos")
        
        # Unir todos los segmentos
        transcript = " ".join([segment.text for segment in segments])
        
        print(f"âœ… TranscripciÃ³n completada: {len(transcript)} caracteres")
        return transcript.strip()
